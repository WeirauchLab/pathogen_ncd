{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name:\n",
    "        ukb_tnx_phecode_combining_results_pub.ipynb\n",
    "\n",
    "Author:   \n",
    "        Mike Lape\n",
    "\n",
    "Date:  \n",
    "        2024\n",
    "\n",
    "Description:\n",
    "\n",
    "        This notebook takes in the UKB Phecode results as well as the TNX Phecode \n",
    "        results and combines them to give final answers about replicated results. \n",
    "        Those being significant in UKB and then also being significant in TNX \n",
    "        with the odds ratios agreeing in direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data science\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from statsmodels.stats.multitest import multipletests as mt\n",
    "\n",
    "# Plots\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Working with dates\n",
    "from datetime import date,datetime\n",
    "import dateutil\n",
    "\n",
    "# Looping  progress\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Reg expressions\n",
    "import re\n",
    "\n",
    "# Pretty table printing\n",
    "import tabulate\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Misc libraries\n",
    "from IPython.display import display, HTML\n",
    "#from IPython.core.display import display, HTML\n",
    "\n",
    "# Set seaborn figure size, font size, and style\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Set Pandas options so we can see our entire dataframe\n",
    "pd.options.display.max_rows = 10000\n",
    "pd.options.display.max_columns = 10000\n",
    "pd.options.display.max_colwidth = None\n",
    "\n",
    "# Print our versions of this packages, this allows us to make sure\n",
    "# we have the working versions we need. \n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "\n",
    "\n",
    "# Remove grey side bars\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"/data/pathogen_ncd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the separate TNX result files together to have a set of final TNX \n",
    "results\n",
    "\n",
    "```bash\n",
    "\n",
    "RES_DIR=\"${HOME_DIR}/phecode/tnx/path_analysis\"\n",
    "\n",
    "res=\"${RES_DIR}/res\"\n",
    "\n",
    "res_fp=\"${RES_DIR}/phecode_collected_res_12_5.tsv\"\n",
    "\n",
    "# Combine all result files \n",
    "cat \"${res}\"/phe_*_results.tsv > \"${res_fp}\"\n",
    "\n",
    "# Grab the header\n",
    "head -n1 \"${res_fp}\"  > header\n",
    "\n",
    "# Remove all header lines that are all throughout the file\n",
    "grep -v  \"Disease_Description\" \"${res_fp}\" | sponge \"${res_fp}\"\n",
    "\n",
    "# Now just add 1 header line in at top of file\n",
    "cat header \"${res_fp}\" | sponge \"${res_fp}\"\n",
    "\n",
    "rm -v header\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep UKB and TNX results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in UKB and TNX Result Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UKB results file\n",
    "all_ukb = pd.read_excel(f'{HOME_DIR}/phecode/ukb/path_analysis/ukb_phecode_results_MCC_of_ONE_2024_10_22_with_std_lev.xlsx',\n",
    "                        dtype = {'phecode' : str})\n",
    "all_ukb.loc[:, ['nCase', 'nControl']] = all_ukb.loc[:, ['nCase', 'nControl']].astype(int)\n",
    "all_ukb['num_tot_samples'] = all_ukb['nCase'] + all_ukb['nControl']\n",
    "all_ukb = all_ukb.rename(columns = {'organism' : 'org', 'Phecode' : 'phecode', 'Antigen' : 'anti'})\n",
    "\n",
    "# TNX categorical test results\n",
    "all_tnx_cat = pd.read_csv(f'{HOME_DIR}/phecode/tnx/path_analysis/res/phecode_collected_res_12_5.tsv', \n",
    "                          dtype = {'phecode' : str}, sep = '\\t')\n",
    "\n",
    "all_tnx = all_tnx_cat.copy(deep = True)\n",
    "all_tnx.loc[:, ['num_case', 'num_con']] = all_tnx.loc[:, ['num_case', 'num_con']].astype(int)\n",
    "all_tnx['num_tot_samples'] = all_tnx['num_case'] + all_tnx['num_con']\n",
    "all_tnx['mcc'] = 'mcc1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Number of rows in clean Path data: 21,900\n",
    "\n",
    "# All orgs have 1,095 results\n",
    "all_ukb['org'].value_counts(dropna = False)\n",
    "\n",
    "# All phecodes have 20 results\n",
    "all_ukb['phecode'].value_counts(dropna = False)\n",
    "\n",
    "# 1,095 unique Phecodes each with 20 orgs = 21,900\n",
    "# 21,900\n",
    "print(all_ukb.shape[0])\n",
    "\n",
    "# All orgs have variable # results\n",
    "all_tnx['org'].value_counts(dropna = False)\n",
    "\n",
    "# All phecodes have variable # results\n",
    "all_tnx['phecode'].value_counts(dropna = False)\n",
    "\n",
    "# 437 Phecodes each with variable number of tests.\n",
    "# 117,966- only ran UKB sig\n",
    "print(all_tnx.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align UKB and TNX Pathogen tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UKB and TNX Anti's are already aligned\n",
    "# Fix some weird chars\n",
    "all_ukb.loc[:, 'org'] = all_ukb.loc[:, 'org'].replace({'MCV\\xa0' : 'MCV', \n",
    "                                                   'H.\\xa0pylori' : 'H.pylori'})\n",
    "all_tnx.loc[:, 'org'] = all_tnx.loc[:, 'org'].replace({'MCV\\xa0' : 'MCV', \n",
    "                                                   'H.\\xa0pylori' : 'H.pylori'})\n",
    "\n",
    "org_to_tag_dict = {\n",
    "                            'HSV1'           : 'hsv1',\n",
    "                            'hsv_1'          : 'hsv1',\n",
    "                            'HSV2'           : 'hsv2',\n",
    "                            'hsv_2'          : 'hsv2',\n",
    "                            'VZV'            : 'vzv',\n",
    "                            'EBV'            : 'ebv',\n",
    "                            'CMV'            : 'cmv',\n",
    "                            'HHV-6'          : 'hhv6',\n",
    "                            'hhv_6'          : 'hhv6',\n",
    "                            'HHV-7'          : 'hhv7',\n",
    "                            'hhv_7'          : 'hhv7',\n",
    "                            'KSHV/HHV-8'     : 'kshv',\n",
    "                            'HBV'            : 'hbv',\n",
    "                            'HCV'            : 'hcv',\n",
    "                            'T. gondii'      : 'tox',\n",
    "                            'T.gondii'       : 'tox',\n",
    "                            't_gond'         : 'tox',\n",
    "                            'HTLV-1'         : 'htlv',\n",
    "                            'BKV'            : 'bkv',\n",
    "                            'JCV'            : 'jcv',\n",
    "                            'MCV'            : 'mcv',\n",
    "                            'HPV-16'         : 'hpv16',\n",
    "                            'hpv_16'         : 'hpv16',\n",
    "                            'HPV-18'         : 'hpv18',\n",
    "                            'hpv_18'         : 'hpv18',\n",
    "                            'C. trachomatis' : 'chlam',\n",
    "                            'C.trachomatis'  : 'chlam',\n",
    "                            'c_trach'        : 'chlam',\n",
    "\n",
    "                            'H.pylori'       : 'hpylori',\n",
    "                            'h_pylor'        : 'hpylori',\n",
    "    \n",
    "                            'HIV'            : 'hiv'\n",
    "                        }\n",
    "\n",
    "all_ukb['tag'] = all_ukb.loc[:, 'org'].replace(org_to_tag_dict)\n",
    "all_tnx['tag'] = all_tnx.loc[:, 'org'].replace(org_to_tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'mcv'}\n",
    "# No TNX results for MCV - expected\n",
    "print(set(all_ukb['tag'].unique().tolist()).difference(set(all_tnx['tag'].unique().tolist())))\n",
    "\n",
    "# {}\n",
    "# No pathogens in UKB results that aren't also in TNX results\n",
    "print(set(all_tnx['tag'].unique().tolist()).difference(set(all_ukb['tag'].unique().tolist())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do statistical power filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case and Total Sample Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical power requirements\n",
    "MIN_CASE_THRESH = 17\n",
    "MIN_TOT_SAMP_THRESH  = 187\n",
    "\n",
    "# Tier 1 phecodes - the reverse would be expected negative\n",
    "\n",
    "# | Phecode | Disease_Description        | Disease_Group       | ICD10(s) in PheCode     | ICDs not in ICD10-based Tier 1 | ICDs in ICD10-based Tier 1 | is_interesting | man_rev_interested | Tier 1 Pathogen | Notes                                                                                |\n",
    "# |---------|----------------------------|---------------------|-------------------------|--------------------------------|----------------------------|----------------|--------------------|-----------------|--------------------------------------------------------------------------------------|\n",
    "# | 053     | Herpes zoster              | infectious diseases | B02, G53                | G53                            | B02                        | Y              | Y                  | VZV             | G53.0: Postzoster neuralgia                                                          |\n",
    "# | 054     | Herpes simplex             | infectious diseases | A60, B00, B08           | B08                            | A60, B00                   | Y              | Y                  | HSV1, HSV2      | B08.8: Other forms of   herpesviral infection                                        |\n",
    "# | 070     | Viral   hepatitis          | infectious diseases | B17, B18, B19           | B17, B18                       | B19                        | Y              | Y                  | HBV, HCV        |                                                                                      |\n",
    "# | 070.2   | Viral   hepatitis B        | infectious diseases | B16, B18                | B16, B18                       | -                          | Y              | Y                  | HBV             |                                                                                      |\n",
    "# | 070.3   | Viral hepatitis C          | infectious diseases | B17, B18                | B17, B18                       | -                          | Y              | Y                  | HCV             |                                                                                      |\n",
    "# | 070.9   | Hepatitis NOS              | infectious diseases | K71, K75, K76           | K71                            | K75, K76                   | Y              | Y                  | HBV, HCV        |                                                                                      |\n",
    "# | 071     | HIV infection, symptomatic | infectious diseases | B20, B21, B22, B23, B24 | B20, B21, B22, B23             | B24                        | Y              | Y                  | HIV             | All codes mean they have HIV   infection, just usually indicate additional infection |\n",
    "# | 078     | Viral warts & HPV          | infectious diseases | A63, B07                | A63, B07                       | -                          | Y              | Y                  | HPV16, HPV18    |                                                                                      |\n",
    "# | 079.2   | Infectious mononucleosis   | infectious diseases | B27                     |                                | B27                        | Y              | Y                  | EBV             | Exact match B27 only                                                                 |\n",
    "\n",
    "tier_1_phecodes = ['053', '054', '070', '070.2', '070.3', '070.9', '071', '078', '079.2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total in UKB:  21900\n",
    "# Total in UKB that meet case threshold [n >= 17]:  21900\n",
    "# Total in TNX:  117966\n",
    "# Total in TNX stds:  926\n",
    "# Total in TNX non-stds:  117040\n",
    "# Total in TNX standards that meet case threshold [n >= 17] and total sample threshold [n >= 187]:  864\n",
    "# Total in TNX non-standards that meet case threshold [n >= 17] and total sample threshold [n >= 187]:  107908\n",
    "# Total in combined TNX that meet thresholds: 108772\n",
    "\n",
    "print(f\"Total in UKB:  {len(all_ukb)}\")\n",
    "ukb = all_ukb.copy(deep = True)\n",
    "ukb = ukb.loc[((ukb['phecode'].isin(tier_1_phecodes)) | \n",
    "         ((ukb['nCase'] >= MIN_CASE_THRESH) &\n",
    "          (ukb['num_tot_samples'] >= MIN_TOT_SAMP_THRESH))), :]\n",
    "\n",
    "print(f\"Total in UKB that meet case threshold [n >= {MIN_CASE_THRESH}]:  {len(ukb)}\")\n",
    "\n",
    "\n",
    "print(f\"Total in TNX:  {len(all_tnx)}\")\n",
    "tnx_stds = all_tnx.loc[all_tnx['phecode'].isin(tier_1_phecodes), :]\n",
    "tnx_non_stds = all_tnx.loc[~all_tnx['phecode'].isin(tier_1_phecodes), :]\n",
    "print(f\"Total in TNX stds:  {len(tnx_stds)}\")\n",
    "print(f\"Total in TNX non-stds:  {len(tnx_non_stds)}\")\n",
    "\n",
    "tnx_stds = tnx_stds.loc[((tnx_stds['num_case'] >= MIN_CASE_THRESH) &\n",
    "                         (tnx_stds['num_tot_samples'] >= MIN_TOT_SAMP_THRESH)), :]\n",
    "print(f\"Total in TNX standards that meet case threshold [n >= {MIN_CASE_THRESH}] and total sample threshold [n >= {MIN_TOT_SAMP_THRESH}]:  {len(tnx_stds)}\")\n",
    "\n",
    "tnx_non_stds = tnx_non_stds.loc[((tnx_non_stds['num_case'] >= MIN_CASE_THRESH) &\n",
    "                   (tnx_non_stds['num_tot_samples'] >= MIN_TOT_SAMP_THRESH)), :]\n",
    "print(f\"Total in TNX non-standards that meet case threshold [n >= {MIN_CASE_THRESH}] and total sample threshold [n >= {MIN_TOT_SAMP_THRESH}]:  {len(tnx_non_stds)}\")\n",
    "\n",
    "tnx = pd.concat([tnx_stds, tnx_non_stds])\n",
    "print(f\"Total in combined TNX that meet thresholds: {len(tnx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work on UKB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate per-disease FDR corrected NOMINAL p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phe_ls = ukb['phecode'].unique().tolist()\n",
    "\n",
    "fin_ukb_ls = [] \n",
    "for curr_phe in tqdm(phe_ls):\n",
    "    curr_dis_res = ukb.loc[ukb['phecode'] == curr_phe, :].copy(deep = True)\n",
    "\n",
    "    curr_dis_res['per_dis_bh_fdr_corr_nom_p'] = mt(curr_dis_res['p_val'], \n",
    "                                                   alpha = 0.05, method = 'fdr_bh')[1]\n",
    "\n",
    "    fin_ukb_ls.extend(curr_dis_res.values.tolist())\n",
    "    \n",
    "fin_ukb = pd.DataFrame(fin_ukb_ls, columns = ukb.columns.tolist() + ['per_dis_bh_fdr_corr_nom_p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work on TNX results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limit TNX to selected UKB dis-org pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Orgs:\")\n",
    "print(sorted(list(set(tnx['tag'].unique().tolist()).difference(set(ukb['tag'].unique().tolist())))))\n",
    "print(sorted(list(set(ukb['tag'].unique().tolist()).difference(set(tnx['tag'].unique().tolist())))))\n",
    "\n",
    "print(\"Antibodies:\")\n",
    "print(sorted(list(set(tnx['anti'].unique().tolist()).difference(set(ukb['anti'].unique().tolist())))))\n",
    "print(sorted(list(set(ukb['anti'].unique().tolist()).difference(set(tnx['anti'].unique().tolist())))))\n",
    "\n",
    "print(\"Diseases:\")\n",
    "print(sorted(list(set(tnx['phecode'].unique().tolist()).difference(set(ukb['phecode'].unique().tolist())))))\n",
    "print(sorted(list(set(ukb['phecode'].unique().tolist()).difference(set(tnx['phecode'].unique().tolist())))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some diseases in TNX that are not in UKB results most likely filtered out\n",
    "# by minimum number of case/control requirements\n",
    "\n",
    "# No TNX tests for the following orgs: \n",
    "# 'hhv7'\n",
    "# 'htlv': Only org for U14 so that shows up in diff of Abs.\n",
    "# 'mcv'\n",
    "\n",
    "# No UKB results for the following Phecodes by BH Corrected NOMINAL P:\n",
    "\n",
    "# No TNX diags for the following Phecodes:\n",
    "# '008.52', '041.2', '041.21', '078', '081', '1000', '1001', '1006', \n",
    "# '1015', '110.12', '110.2', '1100', '112.3', '117', '157', '165.1', \n",
    "# '170', '170.2', '172', '172.1', '172.11', '184.1', '187', '189.1', \n",
    "# '189.11', '191', '191.1', '193', '198.5', '202.2', '202.24', '204.2', \n",
    "# '208', '212', '214', '215', '222', '225', '225.1', '227', '227.2', \n",
    "# '229', '242', '244.1', '246', '250.4', '250.5', '250.7', '251', \n",
    "# '252', '252.1', '256.4', '260.6', '261', '261.2', '271', '271.3', \n",
    "# '272.9', '274.11', '274.2', '275', '275.1', '276.1', '276.11', \n",
    "# '276.14', '276.4', '277', '277.4', '277.5', '278', '278.1', '279', \n",
    "# '280.2', '281.11', '281.12', '282', '284', '285.22', '286.7', \n",
    "# '287.31', '290', '290.1', '290.11', '290.2', '292', '292.3', '292.4', \n",
    "# '292.6', '295', '295.1', '296', '296.1', '296.2', '296.22', '300.1',\n",
    "# '300.11', '300.13', '300.9', '301', '302.1', '303', '303.3', '305.2', \n",
    "# '306.9', '316', '324', '327', '327.3', '327.4', '327.41', '331', \n",
    "# '331.1', '333', '333.1', '340.1', '342', '344', '345.1', '345.11', \n",
    "# '345.12', '346', '348', '348.2', '348.7', '348.9', '361', '361.1', \n",
    "# '362.3', '362.31', '362.4', '364.4', '364.5', '365', '365.2', '366.2',\n",
    "# '367', '367.9', '368', '368.2', '368.3', '368.9', '370', '371.1', \n",
    "# '371.3', '374.1', '374.3', '378.1', '378.5', '379.1', '379.3', '380',\n",
    "# '380.1', '381.1', '382', '383', '385.3', '386.1', '386.2', '386.3', \n",
    "# '386.9', '388', '389', '389.2', '394.7', '395.4', '395.6', '396', \n",
    "# '401.21', '411.9', '414', '418.1', '420', '420.2', '425.1', '426', \n",
    "# '426.23', '426.3', '426.31', '426.32', '426.9', '426.91', '427.2', '427.3', \n",
    "# '427.41', '427.5', '427.7', '428', '429', '429.2', '429.3', '430.3', \n",
    "# '433', '433.2', '433.21', '433.3', '433.31', '440', '441.1', '444', \n",
    "# '444.1', '446', '446.5', '446.9', '454', '454.11', '458', '458.2', \n",
    "# '458.9', '465.4', '470', '471', '472', '473', '473.3', '480.5', '501',\n",
    "# '504', '509.8', '512.1', '513', '513.4', '516.1', '520', '520.2', '522',\n",
    "# '522.5', '523', '523.1', '523.3', '523.32', '525', '527', '527.2', \n",
    "# '528.1', '528.11', '528.12', '528.6', '529', '530.2', '530.9', '535.1', \n",
    "# '537', '540.1', '550.1', '550.3', '550.4', '555.1', '559', '560.3', \n",
    "# '564.9', '568', '568.1', '569.1', '569.2', '572', '573.3', '573.5', \n",
    "# '574.12', '575.1', '578.1', '578.2', '578.9', '579', '580.14', '580.3', \n",
    "# '580.32', '585.3', '586.1', '586.11', '590', '594', '594.1', '594.2', \n",
    "# '594.3', '596.1', '598.9', '599', '599.2', '599.9', '600', '601', \n",
    "# '601.12', '601.4', '610.2', '610.4', '612', '612.2', '613', '613.1', \n",
    "# '613.7', '613.8', '613.9', '614.1', '614.51', '614.53', '615', '618.2',\n",
    "# '619.2', '619.3', '619.5', '621', '622', '622.1', '622.2', '623', \n",
    "# '625.1', '626.11', '626.12', '626.14', '626.4', '626.8', '627', '627.4',\n",
    "# '628', '634.3', '635', '635.2', '635.3', '645', '647', '651', '652', \n",
    "# '653', '679', '681.2', '686.2', '686.4', '687.1', '690', '690.1', '691',\n",
    "# '695.3', '695.8', '696.3', '696.42', '701.2', '701.5', '704.2', '704.8',\n",
    "# '705.1', '709', '709.2', '709.7', '716.2', '720', '721.8', '722.1', \n",
    "# '722.7', '723', '723.1', '724', '724.9', '726.3', '728', '728.7', \n",
    "# '728.71', '732.1', '735.2', '735.23', '736', '736.2', '738', '740.11', \n",
    "# '742', '742.9', '743.2', '747.11', '747.12', '751', '751.11', '751.22', \n",
    "# '752', '752.1', '755', '756', '766', '771', '772', '781', '797', \n",
    "# '798.1', '800', '800.2', '800.3', '801', '803.1', '803.3', '804', \n",
    "# '830', '840', '850', '851', '854', '857', '870.1', '870.5', '871', \n",
    "# '913', '915', '916', '949', '958', '960', '960.2', '979', '990'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Limit TNX Results to just UKB Significant Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total in combined TNX that meet thresholds: 69595\n",
    "\n",
    "# 108,772\n",
    "print(len(tnx))\n",
    "\n",
    "ukb_vals = fin_ukb.loc[:, ['phecode', 'tag', 'anti']].values.tolist()\n",
    "\n",
    "filt_tnx_ls = []\n",
    "for curr_phecode, curr_org, curr_anti in tqdm(ukb_vals):\n",
    "    \n",
    "    sel_tnx = tnx.loc[((tnx['phecode'] == curr_phecode) & \n",
    "                       (tnx['tag'] == curr_org) &\n",
    "                       (tnx['anti'] == curr_anti)), :].values.tolist()\n",
    "\n",
    "\n",
    "    filt_tnx_ls.extend(sel_tnx)\n",
    "    \n",
    "filt_tnx = pd.DataFrame(filt_tnx_ls, columns = tnx.columns)\n",
    "\n",
    "# 108,772\n",
    "print(len(filt_tnx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21,900\n",
    "print(len(fin_ukb.loc[:, ['phecode', 'tag', 'anti']].drop_duplicates()))\n",
    "\n",
    "# 11,218\n",
    "print(len(filt_tnx.loc[:, ['phecode', 'tag', 'anti']].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate TNX per-phecode FDR corrected NOMINAL p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_tnx.loc[:, 'p_val'] = filt_tnx.loc[:, 'p_val'].astype(float)\n",
    "\n",
    "phe_ls = filt_tnx['phecode'].unique().tolist()\n",
    "\n",
    "fin_tnx_ls = [] \n",
    "for curr_phecode in tqdm(phe_ls):\n",
    "    curr_dis_res = filt_tnx.loc[filt_tnx['phecode'] == curr_phecode, :].copy(deep = True)\n",
    "\n",
    "    curr_dis_res['per_dis_bh_fdr_corr_p'] = mt(curr_dis_res['p_val'], \n",
    "                                                   alpha = 0.05, method = 'fdr_bh')[1]\n",
    "\n",
    "    fin_tnx_ls.extend(curr_dis_res.values.tolist())\n",
    "    \n",
    "fin_tnx = pd.DataFrame(fin_tnx_ls, columns = filt_tnx.columns.tolist() + ['per_dis_bh_fdr_corr_p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge cleaned UKB and cleaned TNX results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_ukb.columns = [f'ukb_{x}' for x in fin_ukb.columns.tolist()] \n",
    "fin_tnx.columns = [f'tnx_{x}' for x in fin_tnx.columns.tolist()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nrow UKB: 21900\n",
    "# nrow TNX: 108772\n",
    "# nrow combo: 119454\n",
    "print(f\"nrow UKB: {len(fin_ukb)}\")\n",
    "print(f\"nrow TNX: {len(fin_tnx)}\")\n",
    "\n",
    "combo = fin_ukb.merge(fin_tnx, how = 'left',\n",
    "                      left_on = ['ukb_phecode', 'ukb_tag', 'ukb_anti'],\n",
    "                      right_on = ['tnx_phecode', 'tnx_tag', 'tnx_anti'])\n",
    "\n",
    "print(f\"nrow combo: {len(combo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 108,772\n",
    "len(combo.loc[~combo['tnx_phecode'].isna(),: ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = combo.loc[:, ['ukb_Disease_Description', 'ukb_Disease_Group', 'ukb_phecode', \n",
    "                      'ukb_tag', 'ukb_anti',  'ukb_std_lev',\n",
    "                      'tnx_test_type', 'tnx_test_id', 'tnx_test', 'tnx_mod_method',\n",
    "                      'ukb_sex_specific_dis', 'ukb_nCase', 'ukb_nControl',\n",
    "                      'ukb_control_set', \n",
    "                      'tnx_dis_sex_str', 'tnx_num_case', 'tnx_num_con',\n",
    "                      'tnx_con_str', 'tnx_n_mixed',\n",
    "                      \n",
    "                      'ukb_per_dis_bh_fdr_corr_nom_p', 'ukb_p_val',\n",
    "                      'tnx_per_dis_bh_fdr_corr_p', 'tnx_p_val',\n",
    "\n",
    "                      \n",
    "                      'ukb_anti_OR',  'tnx_OR',\n",
    "\n",
    "                      'ukb_sig_covs', 'ukb_cov_adj_for',\n",
    "                      \n",
    "                      'ukb_Warnings', 'ukb_is_warning',\n",
    "                      'tnx_glm_warn_msg', 'tnx_glm_warn_bool',\n",
    "                      \n",
    "                      'ukb_model', 'tnx_model',\n",
    "                      \n",
    "                      'ukb_cov_ps',  'ukb_cov_ors', 'tnx_cov_adj',\n",
    "                      'tnx_cov_ps', 'tnx_cov_or',\n",
    "                      'ukb_anti_CI',  'tnx_CI',\n",
    "\n",
    "                      \n",
    "                      'ukb_avg_age_case',  'ukb_avg_avg_con', \n",
    "                      'ukb_avg_titer_case', 'ukb_avg_titer_con',\n",
    "                      'ukb_std_titer_case', 'ukb_std_titer_con', \n",
    "                      'ukb_med_titer_case', 'ukb_med_titer_con',\n",
    "                       \n",
    "                      'tnx_case_age', 'tnx_con_age', 'tnx_case_titer', 'tnx_con_titer',\n",
    "                      'tnx_case_titer_std', 'tnx_con_titer_std',\n",
    "                      'tnx_case_titer_med', 'tnx_con_titer_med',\n",
    "                      'tnx_n_con_neg', 'tnx_n_con_pos', 'tnx_n_case_neg', 'tnx_n_case_pos',\n",
    "                      'tnx_log_trans', \n",
    "                      \n",
    "                      \n",
    "                      'tnx_note_str',\n",
    "                     ]]\n",
    "\n",
    "combo = combo.rename(columns = {\n",
    "                         'ukb_Disease_Description' : 'Disease_Description',\n",
    "                         'ukb_Disease_Group' : 'Disease_Group',\n",
    "                         'ukb_phecode' : 'phecode',\n",
    "                         'ukb_tag' : 'org',\n",
    "                         'ukb_anti' : 'anti',\n",
    "                         'ukb_std_lev' : 'std_lev',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combo verified to have:\n",
    "# See if there are any rows where there is an TNX test (not null)\n",
    "# and the disease sexes don't match\n",
    "\n",
    "# All good - empty\n",
    "print(combo.loc[((combo['ukb_sex_specific_dis'] != combo['tnx_dis_sex_str']) &\n",
    "           (combo['tnx_test_type'].notnull())), :])\n",
    "\n",
    "# Also, make sure the control sets are the same for both UKB and TNX\n",
    "# All good - empty \n",
    "print(combo.loc[((combo['ukb_control_set'] != combo['tnx_con_str']) &\n",
    "           (combo['tnx_test_type'].notnull())), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert some columns to ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 108,772\n",
    "sum(combo.loc[:, 'tnx_n_mixed'].notnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo.loc[:, ['ukb_nCase', 'ukb_nControl', \n",
    "              'tnx_num_case', 'tnx_num_con']] = combo.loc[:, ['ukb_nCase', 'ukb_nControl', \n",
    "                                                              'tnx_num_case', 'tnx_num_con']].astype(\"Int64\")\n",
    "\n",
    "# Workaround for apparently known bug?\n",
    "# https://stackoverflow.com/a/60024263\n",
    "combo.loc[:, 'tnx_n_mixed'] = combo.loc[:, 'tnx_n_mixed'].astype(\"Int64\")\n",
    "combo.loc[:, 'tnx_n_con_neg'] = combo.loc[:, 'tnx_n_con_neg'].astype(\"Int64\")\n",
    "combo.loc[:, 'tnx_n_con_pos'] = combo.loc[:, 'tnx_n_con_pos'].astype(\"Int64\")\n",
    "combo.loc[:, 'tnx_n_case_neg'] = combo.loc[:, 'tnx_n_case_neg'].astype(\"Int64\")\n",
    "combo.loc[:, 'tnx_n_case_pos'] = combo.loc[:, 'tnx_n_case_pos'].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify type conversion\n",
    "combo.loc[:, ['ukb_nCase', 'ukb_nControl', \n",
    "              'tnx_num_case', 'tnx_num_con', 'tnx_n_mixed', \n",
    "              'tnx_n_con_neg', 'tnx_n_con_pos', \n",
    "              'tnx_n_case_neg', 'tnx_n_case_pos']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo.loc[:, ['ukb_anti_OR', 'tnx_OR']] = combo.loc[:, ['ukb_anti_OR', 'tnx_OR']].astype(float)\n",
    "\n",
    "combo['ukb_risk'] = False\n",
    "combo.loc[combo['ukb_anti_OR'] > 1, 'ukb_risk'] = True\n",
    "\n",
    "combo['tnx_risk'] = False\n",
    "combo.loc[combo['tnx_OR'] > 1, 'tnx_risk'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapse to best TNX result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make small function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to round, but if the decimal cannot be represented by the number of digits we switch to\n",
    "# sci notation with that many digits in the significand.\n",
    "def make_small(num, digits):\n",
    "    if digits < 1:\n",
    "        print(\"Requires positive number of digits\")\n",
    "        return\n",
    "\n",
    "    dig_min_1 = digits - 1\n",
    "\n",
    "    low_bound = 1 / (10 ** (dig_min_1))\n",
    "    up_bound = 10 ** (dig_min_1)\n",
    "\n",
    "    if ((num < low_bound) | (num > up_bound)):\n",
    "        #print(f\"{low_bound} < X < {up_bound} : No\")\n",
    "        return \"{:.{}e}\".format(num, dig_min_1)\n",
    "\n",
    "    return round(num, digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual loop to collapse TNX results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phe_org_ls = combo.loc[:, ['phecode', 'org']].drop_duplicates().values.tolist()\n",
    "\n",
    "fin_combo_ls = []\n",
    "for curr_phe, curr_org in tqdm(phe_org_ls):\n",
    "    \n",
    "    #print(f\"{curr_icd} {curr_org}\")\n",
    "    curr_res = combo.loc[((combo['phecode'] == curr_phe) &\n",
    "                          (combo['org'] == curr_org)), :].copy(deep = True)\n",
    "\n",
    "    \n",
    "    # No TNX tests\n",
    "    if (len(curr_res) == 1) & (all(curr_res['tnx_test_id'].isna())):\n",
    "\n",
    "        curr_res['other_test_str'] = ''\n",
    "        curr_res['or_flip_tnx_tests'] = ''\n",
    "\n",
    "        fin_combo_ls.extend(curr_res.values.tolist())\n",
    "\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    # If organism is risk\n",
    "    is_ukb_risk = curr_res['ukb_risk'].unique().tolist()[0]\n",
    "\n",
    "    # Risk\n",
    "    if is_ukb_risk:\n",
    "\n",
    "        curr_tnx_res = curr_res.loc[curr_res['tnx_risk'] == True, :]\n",
    "        curr_tnx_opp_res = curr_res.loc[curr_res['tnx_risk'] == False, :]\n",
    "\n",
    "    # Protective\n",
    "    else:\n",
    "\n",
    "        curr_tnx_res = curr_res.loc[curr_res['tnx_risk'] == False, :]\n",
    "        curr_tnx_opp_res = curr_res.loc[curr_res['tnx_risk'] == True, :]\n",
    "\n",
    "    curr_tnx_res = curr_tnx_res.sort_values(['tnx_per_dis_bh_fdr_corr_p'], ascending = True).reset_index(drop = True)\n",
    "\n",
    "    \n",
    "    # No tests in the same direction, so get most sig in oppsite direction\n",
    "    if len(curr_tnx_res) == 0:    \n",
    "        curr_tnx_opp_res = curr_tnx_opp_res.sort_values(['tnx_per_dis_bh_fdr_corr_p'], ascending = True).reset_index(drop = True)\n",
    "        # get most sig TNX p\n",
    "        best_tnx = curr_tnx_opp_res.iloc[0].copy(deep = True)\n",
    "\n",
    "        # Grab the rest of the tests (less sig)\n",
    "        rest_tnx = curr_tnx_opp_res.iloc[1:].copy(deep = True)\n",
    "        rest_tnx = rest_tnx.reset_index(drop = True)\n",
    "\n",
    "        \n",
    "        # Throw the rest of the tests in a column of best_tnx\n",
    "        if len(rest_tnx) > 0:\n",
    "            best_tnx['or_flip_tnx_tests'] =  rest_tnx.agg( lambda x: f\"{x['tnx_test_id']} [{x['tnx_test']}, {x['tnx_mod_method']}]:  nCase: {x['tnx_num_case']} | nCon: {x['tnx_num_con']}, corr p-val: {make_small(x['tnx_per_dis_bh_fdr_corr_p'],3)}, uncorr p-val: {make_small(x['tnx_p_val'], 3)}, OR: {make_small(x['tnx_OR'], 3)} | model: {x['tnx_model']}, glm_warn [{x['tnx_glm_warn_bool']}]: {x['tnx_glm_warn_msg']} log10 trans: {x['tnx_log_trans']} | Notes: {x['tnx_note_str']}\", axis = 1)\n",
    "        else:\n",
    "            best_tnx['or_flip_tnx_tests'] = ''\n",
    "\n",
    "\n",
    "        if len(curr_tnx_opp_res) > 0:\n",
    "            best_tnx['other_test_str'] =  curr_tnx_opp_res.agg( lambda x: f\"{x['tnx_test_id']} [{x['tnx_test']}, {x['tnx_mod_method']}]:  nCase: {x['tnx_num_case']} | nCon: {x['tnx_num_con']}, corr p-val: {make_small(x['tnx_per_dis_bh_fdr_corr_p'],3)}, uncorr p-val: {make_small(x['tnx_p_val'], 3)}, OR: {make_small(x['tnx_OR'], 3)} | model: {x['tnx_model']}, glm_warn [{x['tnx_glm_warn_bool']}]: {x['tnx_glm_warn_msg']} log10 trans: {x['tnx_log_trans']} | Notes: {x['tnx_note_str']}\", axis = 1)\n",
    "        else:\n",
    "            best_tnx['other_test_str'] = ''\n",
    "\n",
    "        fin_combo_ls.append(best_tnx.values.tolist())\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        # get most sig TNX p\n",
    "        best_tnx = curr_tnx_res.iloc[0].copy(deep = True)\n",
    "\n",
    "        # Grab the rest of the tests (less sig)\n",
    "        rest_tnx = curr_tnx_res.iloc[1:].copy(deep = True)\n",
    "        rest_tnx = rest_tnx.reset_index(drop = True)\n",
    "\n",
    "        # Throw the rest of the tests in a column of best_tnx\n",
    "        if len(rest_tnx) > 0:\n",
    "            best_tnx['other_test_str'] =  rest_tnx.agg( lambda x: f\"{x['tnx_test_id']}  [{x['tnx_test']}, {x['tnx_mod_method']}]:  nCase: {x['tnx_num_case']} | nCon: {x['tnx_num_con']}, corr p-val: {make_small(x['tnx_per_dis_bh_fdr_corr_p'],3)}, uncorr p-val: {make_small(x['tnx_p_val'], 3)}, OR: {make_small(x['tnx_OR'], 3)} | model: {x['tnx_model']}, glm_warn [{x['tnx_glm_warn_bool']}]: {x['tnx_glm_warn_msg']} log10 trans: {x['tnx_log_trans']} | Notes: {x['tnx_note_str']}\", axis = 1)\n",
    "        else:\n",
    "            best_tnx['other_test_str'] = ''\n",
    "\n",
    "\n",
    "        if len(curr_tnx_opp_res) > 0:\n",
    "            best_tnx['or_flip_tnx_tests'] =  curr_tnx_opp_res.agg( lambda x: f\"{x['tnx_test_id']} [{x['tnx_test']}, {x['tnx_mod_method']}]:  nCase: {x['tnx_num_case']} | nCon: {x['tnx_num_con']}, corr p-val: {make_small(x['tnx_per_dis_bh_fdr_corr_p'],3)}, uncorr p-val: {make_small(x['tnx_p_val'], 3)}, OR: {make_small(x['tnx_OR'], 3)} | model: {x['tnx_model']}, glm_warn [{x['tnx_glm_warn_bool']}]: {x['tnx_glm_warn_msg']} log10 trans: {x['tnx_log_trans']} | Notes: {x['tnx_note_str']}\", axis = 1)\n",
    "        else:\n",
    "            best_tnx['or_flip_tnx_tests'] = ''\n",
    "\n",
    "        fin_combo_ls.append(best_tnx.values.tolist())\n",
    "    \n",
    "fin_combo = pd.DataFrame(fin_combo_ls, columns = combo.columns.tolist() + ['other_test_str', 'or_flip_tnx_tests'])\n",
    "\n",
    "fin = fin_combo.copy(deep = True)\n",
    "\n",
    "# TNX: 21,900 -> Matching the # UKB Phe-Org pairs\n",
    "print(len(fin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = fin.sort_values(['phecode', 'org', 'ukb_per_dis_bh_fdr_corr_nom_p'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mark replication status for each Disease-Pathogen Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UKB_THRESH = 0.3\n",
    "TNX_THRESH = 0.01\n",
    "\n",
    "org_lev_res = fin.copy(deep = True)\n",
    "\n",
    "# Default: 'did_not_attempt'\n",
    "org_lev_res['rep_stat'] = 'did_not_attempt'\n",
    "\n",
    "\n",
    "# Rep: UKB and TNX sig\n",
    "org_lev_res.loc[((org_lev_res.loc[:, 'ukb_per_dis_bh_fdr_corr_nom_p'] < UKB_THRESH) & \n",
    "                 (org_lev_res.loc[:, 'tnx_per_dis_bh_fdr_corr_p'] < TNX_THRESH)), \n",
    "                'rep_stat'] = 'replicated'\n",
    "\n",
    "\n",
    "# Could not: UKB sig but no TNX test\n",
    "org_lev_res.loc[((org_lev_res.loc[:, 'ukb_per_dis_bh_fdr_corr_nom_p'] < UKB_THRESH ) & \n",
    "                 (org_lev_res['tnx_p_val'].isna())), 'rep_stat'] = 'could_not'\n",
    "\n",
    "\n",
    "# Did not: UKB sig and either (TNX not sig) or (TNX sig but OR in opposite direction of UKB)\n",
    "org_lev_res.loc[(\n",
    "\n",
    "            (org_lev_res['ukb_per_dis_bh_fdr_corr_nom_p'] < UKB_THRESH) & \n",
    "\n",
    "            (\n",
    "                (org_lev_res['tnx_per_dis_bh_fdr_corr_p'] >= TNX_THRESH) |\n",
    "\n",
    "                (\n",
    "                    (org_lev_res.loc[:, 'tnx_per_dis_bh_fdr_corr_p'] < TNX_THRESH) &\n",
    "                    (org_lev_res['ukb_risk'] !=  org_lev_res['tnx_risk'])\n",
    "                )\n",
    "\n",
    "            )\n",
    "        ), 'rep_stat'] = 'did_not'\n",
    "\n",
    "org_lev_res.loc[:, 'std_lev'] = org_lev_res.loc[:, 'std_lev'].replace({\n",
    "                                                            'true_neg' : 'exp_neg',\n",
    "                                                            'Gold' : 'Tier 1',\n",
    "                                                            'Silver' : 'Tier 2',\n",
    "                                                            'unk'   : 'unk'\n",
    "                                                        })\n",
    "\n",
    "org_lev_res['pair_is_associated'] = 'No'\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'replicated', 'pair_is_associated'] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all did not attempt TNX stuff to NA\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_test_type'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_test_id'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_test'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_mod_method'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_dis_sex'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_num_case'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_num_con'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_con_str'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_n_mixed'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_per_dis_bh_fdr_corr_p'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_p_val'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_OR'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_glm_warn_msg'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_glm_warn_bool'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_model'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_cov_adj'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_cov_ps'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_cov_or'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_CI'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_case_age'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_con_age'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_case_titer'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_con_titer'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_case_titer_std'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_con_titer_std'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_case_titer_med'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_con_titer_med'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_n_con_neg'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_n_con_pos'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_n_case_neg'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_n_case_pos'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_log_trans'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_note_str'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'tnx_risk'] = ''\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'other_test_str'] = np.nan\n",
    "org_lev_res.loc[org_lev_res['rep_stat'] == 'did_not_attempt', 'or_flip_tnx_tests'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-org some cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_lev_res = org_lev_res.loc[:, ['Disease_Description', 'Disease_Group', 'phecode', 'org', 'anti', \n",
    "                                  'pair_is_associated',  'std_lev', 'rep_stat', 'tnx_test_type', \n",
    "                                   'tnx_test_id', 'tnx_test', 'tnx_mod_method', 'ukb_sex_specific_dis',\n",
    "                                   'ukb_nCase', 'ukb_nControl', 'ukb_control_set', \n",
    "                                   'tnx_dis_sex', 'tnx_num_case', 'tnx_num_con', 'tnx_con_str',\n",
    "                                   'tnx_n_mixed', 'ukb_per_dis_bh_fdr_corr_nom_p',\n",
    "                                   'tnx_per_dis_bh_fdr_corr_p', 'ukb_p_val',\n",
    "                                   'tnx_p_val', 'ukb_anti_OR', 'tnx_OR', 'ukb_sig_covs', 'ukb_cov_adj_for',\n",
    "                                   'ukb_Warnings', 'ukb_is_warning', 'tnx_glm_warn_msg',\n",
    "                                   'tnx_glm_warn_bool', 'ukb_model', 'tnx_model', 'ukb_cov_ps',\n",
    "                                   'ukb_cov_ors', 'tnx_cov_adj', 'tnx_cov_ps', 'tnx_cov_or', 'ukb_anti_CI',\n",
    "                                   'tnx_CI', 'ukb_avg_age_case', 'ukb_avg_avg_con', 'ukb_avg_titer_case',\n",
    "                                   'ukb_avg_titer_con', 'ukb_std_titer_case', 'ukb_std_titer_con',\n",
    "                                   'ukb_med_titer_case', 'ukb_med_titer_con', 'tnx_case_age',\n",
    "                                   'tnx_con_age', 'tnx_case_titer', 'tnx_con_titer', 'tnx_case_titer_std',\n",
    "                                   'tnx_con_titer_std', 'tnx_case_titer_med', 'tnx_con_titer_med',\n",
    "                                   'tnx_n_con_neg', 'tnx_n_con_pos', 'tnx_n_case_neg', 'tnx_n_case_pos',\n",
    "                                   'tnx_log_trans', \n",
    "                                   'tnx_note_str', 'ukb_risk', 'tnx_risk', 'other_test_str', 'or_flip_tnx_tests']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble final File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since all of the additional metadata we add in the other notebook,\n",
    "# ukb_tnx_icd_combining_results_pub.ipynb, is ICD keyed and I don't think there \n",
    "# is a way to change that, we can't really run that. \n",
    "\n",
    "# So we will output our final file from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integ_res = org_lev_res.copy(deep = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Organism Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load org data file\n",
    "ant_dict = pd.read_excel(f'{HOME_DIR}/dicts/antigen_dict.xlsx', sheet_name = 'Sheet1',\n",
    "                         engine = 'openpyxl', dtype = {'Baltimore' : \"Int64\"})\n",
    "\n",
    "# Fix minor issue with space coding\n",
    "ant_dict.loc[:,'Abbrev'] = ant_dict.loc[:,'Abbrev'].replace({'H.\\xa0pylori' : 'H. pylori'})\n",
    "ant_dict.loc[:,'Abbrev'] = ant_dict.loc[:,'Abbrev'].replace({r'[^\\x00-\\x7F]+':''}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping org_test data org names to significant results org names\n",
    "ant_dict.loc[:,'tag'] = ant_dict.loc[:,'Abbrev'].replace({\n",
    "                                'C. trachomatis' : 'chlam',\n",
    "                                'EBV'            : 'ebv',\n",
    "                                'H. pylori'      : 'hpylori',\n",
    "                                'H.pylori'       : 'hpylori',\n",
    "                                'HBV'            : 'hbv',\n",
    "                                'HCV'            : 'hcv',\n",
    "                                'HSV1'           : 'hsv1',\n",
    "                                'HSV2'           : 'hsv2',\n",
    "                                'CMV'            : 'cmv',\n",
    "                                'HHV-6'          : 'hhv6',\n",
    "                                'HHV-7'          : 'hhv7',\n",
    "                                'HIV'            : 'hiv',\n",
    "                                'JCV'            : 'jcv',\n",
    "                                'HTLV-1'         : 'htlv',\n",
    "                                'T. gondii'      : 'tox',\n",
    "                                'VZV'            : 'vzv',\n",
    "                                'KSHV/HHV-8'     : 'kshv',\n",
    "                                'HPV-16'         : 'hpv16',\n",
    "                                'HPV-18'         : 'hpv18',\n",
    "                                'BKV'            : 'bkv',\n",
    "                                'MCV'            : 'mcv',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set()\n",
    "# set()\n",
    "print(set(integ_res['org'].unique().tolist()).difference(set(ant_dict['tag'].unique().tolist())))\n",
    "print(set(ant_dict['tag'].unique().tolist()).difference(set(integ_res['org'].unique().tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ant = ant_dict.loc[: , ['tag', 'Organism Type', 'Family',  'Sub-family', 'Species', \n",
    "                          'Baltimore', 'Balt_reason', 'Herpes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45 x 8\n",
    "print(ant.shape)\n",
    "\n",
    "ant.drop_duplicates(inplace = True)\n",
    "\n",
    "# 20 x 8\n",
    "print(ant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21,900 x 68\n",
    "print(integ_res.shape)\n",
    "\n",
    "integ_res = pd.merge(integ_res, ant, left_on = 'org',\n",
    "                     right_on = 'tag', how = 'left')\n",
    "\n",
    "# 21,900 x 76\n",
    "print(integ_res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrange some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integ_res = integ_res.rename(columns = {\n",
    "                                            'tag' : 'Pathogen', \n",
    "                                            'phecode' : 'Phecode', \n",
    "                                            'anti' : 'Antibody',\n",
    "                                            'ukb_anti_OR' : 'ukb_OR',\n",
    "                                            'tnx_num_case' : 'tnx_nCase',\n",
    "                                            'tnx_num_con'  : 'tnx_nControl',\n",
    "                                            'ukb_cov_adj_for' : 'ukb_covs',\n",
    "                                            'tnx_cov_adj' : 'tnx_covs',\n",
    "                                            'ukb_avg_avg_con' : 'ukb_avg_age_con',\n",
    "                                            'tnx_case_age' : 'tnx_avg_age_case',\n",
    "                                            'tnx_con_age' : 'tnx_avg_age_con',\n",
    "                                            'Family' : 'Pathogen Family', \n",
    "                                            'Sub-family': 'Pathogen Sub-family' , \n",
    "                                            'Species' : 'Pathogen Species', \n",
    "                                            'Balt_reason' :  'Pathogen Baltimore Reason',\n",
    "                                            'pair_is_associated' : 'Pair is Associated',\n",
    "                                            'std_lev' : 'Standard Level', \n",
    "                                            'rep_stat' : 'Replication Status',\n",
    "                                            'ukb_per_dis_bh_fdr_corr_nom_p': 'UKB FDR',\n",
    "                                            'tnx_per_dis_bh_fdr_corr_p' : 'TNX FDR',\n",
    "                                            'ukb_OR' : 'UKB OR', \n",
    "                                            'tnx_OR' : 'TNX OR',\n",
    "                                            'ukb_nCase' : 'UKB nCase', \n",
    "                                            'ukb_nControl' : 'UKB nControl', \n",
    "                                            'tnx_nCase' : 'TNX nCase', \n",
    "                                            'tnx_nControl' : 'TNX nControl',\n",
    "                                            \n",
    "                                            'tnx_test_id' : 'TNX Test ID', \n",
    "                                            'tnx_test' : 'TNX Test', \n",
    "                                            'tnx_mod_method' : 'TNX Model Meth',\n",
    "                                            'tnx_con_str' : 'tnx_control_set',\n",
    "                                            \n",
    "                                            'ukb_is_warning' : 'ukb_glm_warn_bool', \n",
    "                                            'ukb_Warnings' : 'ukb_glm_warn_msg'\n",
    "                                            })\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integ_res = integ_res.loc[:, [\n",
    "                                    'Disease_Description', 'Disease_Group', 'Phecode', \n",
    "                                    'Pathogen', 'Antibody', \n",
    "                                    'Pair is Associated', 'Standard Level', 'Replication Status',\n",
    "                                    'tnx_test_id', 'tnx_test', 'tnx_mod_method',\n",
    "                                    'UKB FDR', 'TNX FDR', \n",
    "                                    'UKB OR', 'TNX OR', 'UKB CI',\t'TNX CI',\n",
    "                                    'UKB nCase', 'UKB nControl', 'TNX nCase', 'TNX nControl',\n",
    "                                    'TNX Test ID',\t'TNX Test',\t'TNX Model Meth',\n",
    "                                    'ukb_covs', 'tnx_covs', \n",
    "                                    'ukb_control_set', 'tnx_control_set', 'tnx_n_mixed',                        \n",
    "                                    'ukb_model', 'tnx_model',\n",
    "                                    'ukb_avg_titer_case', 'ukb_avg_titer_con',\n",
    "                                    'ukb_std_titer_case', 'ukb_std_titer_con',\n",
    "                                    'ukb_med_titer_case', 'ukb_med_titer_con',\n",
    "                                    'tnx_n_con_neg', 'tnx_n_con_pos', \n",
    "                                    'tnx_n_case_neg', 'tnx_n_case_pos',\n",
    "                                    'ukb_avg_age_case', 'ukb_avg_age_con',\n",
    "                                    'tnx_avg_age_case', 'tnx_avg_age_con',\n",
    "                                    'ukb_p_val','tnx_p_val',\n",
    "                                    'ukb_sig_covs', 'ukb_cov_ps', 'ukb_cov_ors',\n",
    "                                    'tnx_cov_ps', 'tnx_cov_or',\n",
    "                                    'tnx_note_str', 'other_test_str', 'or_flip_tnx_tests',\n",
    "                                    'ukb_glm_warn_bool', 'ukb_glm_warn_msg',\n",
    "                                    'tnx_glm_warn_bool',  'tnx_glm_warn_msg',                            \n",
    "                                    'Pathogen Type', 'Pathogen Family', \n",
    "                                    'Pathogen Sub-family', 'Pathogen Species'                    \n",
    "\n",
    "                              \n",
    "                \n",
    "                         ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    " 'Disease_Description' : 'Phecode disease description',\n",
    " 'Disease_Group' : 'Phecode broad grouping',\n",
    " 'Phecode' : 'Phecode',\n",
    " 'Pathogen' : 'Organism Abbreviation',\n",
    " 'Antibody': 'Antibody with best UKB association result',\n",
    " 'Pair is Associated' : 'Boolean indicating whether this pair is replicated',\n",
    " 'Standard Level' : 'Whether and what kind of standard this disease-organism pair is',\n",
    " 'Replication Status' : 'The UKB-TNX replication status for this dis-org pair',\n",
    " 'UKB FDR' : 'Disease-wide BH FDR adjusted UKB nominal p-value',\n",
    " 'TNX FDR' : 'Disease-wide BH FDR adjusted TNX nominal p-value',\n",
    " 'UKB OR' : 'Odds ratio for UKB titer [continuous]',\n",
    " 'TNX OR' : 'Odds ratio for TNX association test [categorical]',\n",
    " 'UKB CI' : '95% confidence intervals for UKB odds ratio',\n",
    " 'TNX CI' : '95% confidence intervals for TNX odds ratio',\n",
    " 'UKB nCase' : 'Number of cases in UKB analysis',\n",
    " 'UKB nControl' : 'Number of controls in UKB analysis',\n",
    " 'TNX nCase' : 'Number of cases in TNX test analysis',\n",
    " 'TNX nControl' : 'Number of controls in TNX test analysis',    \n",
    " 'TNX Test ID':  'LOINC code for TNX test used for replication',\n",
    " 'TNX Test' : 'Name of TNX test used for replication',\n",
    " 'TNX Model Meth' : 'Logistic regression method used, either GLM or Firth (exact test)',\n",
    " 'ukb_covs' : 'Confounders that UKB logistic regression model was adjusted for',\n",
    " 'tnx_covs' : 'Confounders that TNX logistic regression model was adjusted for, ideally this is the same as ukb_covs, but did not have access to data for some of the possible confounders in the TNX data set',\n",
    " 'ukb_control_set' : \"Controls used for UKB analysis (all, Female, Male, 'O80,O81,O82,O83,O84' (healthy pregnancies)\",\n",
    " 'tnx_control_set' : \"Controls used for TNX analysis (all, Female, Male, 'O80,O81,O82,O83,O84' (healthy pregnancies)\",\n",
    " 'tnx_n_mixed' : 'Number of TNX participants that fell into cases and controls',\n",
    " 'ukb_model' : 'Full UKB logistic regression model, in the form coefficient * coef_name [coef p-value] ',\n",
    " 'tnx_model': 'Full TNX logistic regression model, in the form coefficient * coef_name [coef p-value] ',\n",
    " 'ukb_avg_titer_case' : 'Average titer value for UKB cases',\n",
    " 'ukb_avg_titer_con' : 'Average titer value for UKB controls',\n",
    " 'ukb_std_titer_case': 'Standard deviation for titer value for UKB cases',\n",
    " 'ukb_std_titer_con': 'Standard deviation for titer value for UKB controls',\n",
    " 'ukb_med_titer_case': 'Median titer value for UKB cases',\n",
    " 'ukb_med_titer_con': 'Median titer value for UKB controls',\n",
    " 'tnx_n_con_neg' : 'Number of disease controls with negative test result for this TNX test',\n",
    " 'tnx_n_con_pos' : 'Number of disease controls with positive test result for this TNX test',\n",
    " 'tnx_n_case_neg' : 'Number of disease cases with negative test result for this TNX test',\n",
    " 'tnx_n_case_pos' : 'Number of disease cases with positive test result for this TNX test',    \n",
    " 'ukb_avg_age_case' : 'Average age of UKB disease cases',\n",
    " 'ukb_avg_age_con' : 'Average age of UKB disease controls',\n",
    " 'tnx_avg_age_case' : 'Average age of diseases cases for this TNX test',\n",
    " 'tnx_avg_age_con' : 'Average age of diseases controls for this TNX test',\n",
    " 'ukb_p_val' : 'Unadjusted nominal UKB p-value',\n",
    " 'tnx_p_val' : 'Unadjusted nominal UKB p-value',\n",
    " 'ukb_sig_covs' : 'Covariates that were significantly associated with both disease status and titer level in UKB. This may not be the same as ukb_covs because we applied a backwards elimination procedure to this list of significant covariates to end up with the final list of covariates to adjust for, ukb_covs.',\n",
    " 'ukb_cov_ps' : 'P-values for covariates included in UKB model',\n",
    " 'ukb_cov_ors' : 'Odds ratios for covariates included in UKB model',\n",
    " 'tnx_cov_ps' : 'P-values for covariates included in TNX model',\n",
    " 'tnx_cov_or' : 'Odds ratios for covariates included in TNX model',\n",
    " 'tnx_note_str' : 'Notes about TNX model',\n",
    " 'tnx_note_str' : 'Notes about TNX model',\n",
    " 'other_test_str' : 'Less significant TNX tests that were also run for replication of this pair',\n",
    " 'ukb_glm_warn_bool' : 'Boolean indicating if GLM threw warning for this UKB model',\n",
    " 'ukb_glm_warn_msg' : 'Warning message if any, given by R glm model during UKB logistic regression modeling',\n",
    " 'tnx_glm_warn_bool' : 'Boolean indicating if GLM threw warning for this TNX model',\n",
    " 'tnx_glm_warn_msg': 'Warning message if any, given by R glm model during TNX logistic regression modeling',\n",
    " 'Pathogen Type' : 'What type of organism the current organism is, either virus or bacteria (T. gondii is not really a bacteria though)',\n",
    " 'Pathogen Family' : 'Phylogenetic family of organism',\n",
    " 'Pathogen Sub-family' : 'Phylogenetic sub-family of organism',\n",
    " 'Pathogen Species' : 'Phylogenetic species of organism'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set()\n",
    "# set()\n",
    "print(set(list(data_dict.keys())).difference(set(integ_res.columns.tolist())))\n",
    "print(set(integ_res.columns.tolist()).difference(list(data_dict.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional filtering of Phecode Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = integ_res.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grps_to_keep = ['circulatory system', 'dermatologic', 'digestive', 'endocrine/metabolic', \n",
    "                'genitourinary', 'hematopoietic',  'mental disorders', 'musculoskeletal', \n",
    "                'neoplasms', 'neurological', 'pregnancy complications', 'respiratory', \n",
    "                'sense organs']\n",
    "\n",
    "# Disease groups to remove: Any infectious diseases except our standards, then other\n",
    "#           things that are either not diseases or things we couldn't detect (congenital anom.)\n",
    "grps_to_rem = ['infectious diseases', 'injuries & poisonings','congenital anomalies',\n",
    "               'symptoms']\n",
    "\n",
    "inf_dis_to_keep = res.loc[res['Standard Level'] == 'exp_neg', 'Disease_Description'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to double check HIV in our Tier 1 and expected negatives. \n",
    "# So, we need to remove the results with std_lev of 'NAN' because those \n",
    "# are the HIV with Tier 1 results, which are not valid.\n",
    "\n",
    "# Unknown    21780\n",
    "# exp_neg      104\n",
    "# Tier 1        10\n",
    "# NAN            6\n",
    "res['Standard Level'].value_counts(dropna = False)\n",
    "\n",
    "\n",
    "# std_lev\n",
    "# NAN    6\n",
    "\n",
    "res.loc[((res['Disease_Description'].isin(inf_dis_to_keep)) & \n",
    "          (res['Pathogen'] == 'hiv')), 'Standard Level'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks good!\n",
    "\n",
    "# std_lev\n",
    "# Unknown    21780\n",
    "# exp_neg      104\n",
    "# Tier 1        10\n",
    "res.loc[res['Standard Level'] != 'NAN', 'Standard Level'].value_counts(dropna = False)\n",
    "\n",
    "res = res.loc[res['Standard Level'] != 'NAN', :]\n",
    "\n",
    "\n",
    "# std_lev\n",
    "# Unknown    21780\n",
    "# exp_neg      104\n",
    "# Tier 1        10\n",
    "res['Standard Level'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disease Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disease_Group\n",
    "# digestive                  2460\n",
    "# genitourinary              2360\n",
    "# circulatory system         2240\n",
    "# neoplasms                  1780\n",
    "# sense organs               1640\n",
    "# endocrine/metabolic        1540\n",
    "# musculoskeletal            1360\n",
    "# dermatologic               1320\n",
    "# respiratory                1140\n",
    "# neurological                960\n",
    "# mental disorders            940\n",
    "# hematopoietic               580\n",
    "# pregnancy complications     500\n",
    "\n",
    "# Remove\n",
    "# infectious diseases         740\n",
    "# injuries & poisonings      1100\n",
    "# congenital anomalies        440\n",
    "# symptoms                    520\n",
    "\n",
    "# Take a closer look at. -> These can all be removed\n",
    "    # NaN                                                                280\n",
    "    # Burns                                                              20\n",
    "    # Foreign body injury                                                20\n",
    "    # Symptoms concerning nutrition, metabolism, and development         20\n",
    "    # Other signs and symptoms involving emotional state                 20\n",
    "    # Other symptoms                                                     20\n",
    "    # Crushing injury                                                    20\n",
    "    # Crushing or internal injury to organs                              20\n",
    "    # Injury, NOS                                                        20\n",
    "    # Other tests                                                        20\n",
    "    # Complications of surgical and medical procedures                   20\n",
    "    # Effects of heat, cold and air pressure                             20\n",
    "    # Effects of other external causes                                   20\n",
    "    # Other ill-defined and unknown causes of morbidity and mortality    20\n",
    "    # Family history                                                     20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_lev\n",
    "# Unknown    18820\n",
    "# exp_neg      104\n",
    "# Tier 1        10\n",
    "res.loc[((res['Disease_Group'].isin(grps_to_keep)) | \n",
    "         (res['Disease_Description'].isin(inf_dis_to_keep))), \n",
    "         'std_lev'].value_counts(dropna = False)\n",
    "\n",
    "\n",
    "# We have 114 infectious diseases left which is equal to our \n",
    "# number of positive and negative controls combined, so we are good.\n",
    "\n",
    "# Disease_Group\n",
    "# digestive                  2460\n",
    "# genitourinary              2360\n",
    "# circulatory system         2240\n",
    "# neoplasms                  1780\n",
    "# sense organs               1640\n",
    "# endocrine/metabolic        1540\n",
    "# musculoskeletal            1360\n",
    "# dermatologic               1320\n",
    "# respiratory                1140\n",
    "# neurological                960\n",
    "# mental disorders            940\n",
    "# hematopoietic               580\n",
    "# pregnancy complications     500\n",
    "# infectious diseases         114\n",
    "res.loc[((res['Disease_Group'].isin(grps_to_keep)) | \n",
    "         (res['Disease_Description'].isin(inf_dis_to_keep))), \n",
    "         'Disease_Group'].value_counts(dropna = False)\n",
    "\n",
    "\n",
    "res = res.loc[((res['Disease_Group'].isin(grps_to_keep)) | \n",
    "         (res['Disease_Description'].isin(inf_dis_to_keep))), :]\n",
    "\n",
    "\n",
    "# Everything looks good so let's write out the res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write our file out (supplemental_dataset_3.xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pd.DataFrame.from_dict(data_dict, orient = 'index') \n",
    "data_dict.reset_index(inplace = True, drop = False)\n",
    "data_dict.columns = ['Column Name', 'Meaning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(f'{HOME_DIR}/manuscript/supplemental_datasets/supplemental_dataset_3.xlsx', engine='openpyxl') as writer:\n",
    "    res.to_excel(writer, sheet_name='Results', index=False)\n",
    "    data_dict.to_excel(writer, sheet_name='Dictionary', index=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Name:\n",
    "        pubmed_search_pub.ipynb\n",
    "\n",
    "Author:   \n",
    "        Mike Lape\n",
    "\n",
    "Date:  \n",
    "        2020\n",
    "\n",
    "Description:\n",
    "        This notebook runs the Pubmed crawl so that we can calculate LPF by \n",
    "        first collecting the number of citations for each pathogen alone, each\n",
    "        disease alone, and each pathogen-disease pair. It uses biopython's \n",
    "        Entrez module to search Pubmed for the number of citations. This was\n",
    "        run August 11th, 2020.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "pd.options.display.max_rows = 10000\n",
    "pd.options.display.max_columns = 10000\n",
    "\n",
    "# Set up Entrez\n",
    "from Bio import Entrez\n",
    "Entrez.api_key = \"xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "Entrez.email = \"yyyy@zzzz.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load our lists of search terms (diseases and pathogens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"/data/pathogen_ncd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_ab = pd.read_csv(f\"{HOME_DIR}/misc/a_and_b_disease_data.txt\", \n",
    "                   sep = '\\t', encoding = \"ISO-8859-1\")\n",
    "\n",
    "dis_other = pd.read_csv(f\"{HOME_DIR}/misc/all_other_disease_data.txt\", \n",
    "                   sep = '\\t', encoding = \"ISO-8859-1\")\n",
    "\n",
    "orgs = pd.read_csv(f\"{HOME_DIR}/misc/org_data.txt\", \n",
    "                   sep = '\\t', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease only search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all diseases into a single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = pd.concat([dis_ab, dis_other], ignore_index = True)\n",
    "\n",
    "# Strip out square brackets which for some reason causes esearch to drop from \n",
    "# query!\n",
    "dis['disease'] = dis['disease'].str.replace('\\[|\\]', \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_res = []\n",
    "\n",
    "for x, curr_row in tqdm(dis.iterrows(), total = dis.shape[0]):\n",
    "    curr_dis = curr_row['disease']\n",
    "    \n",
    "    q = f\"({curr_dis})\"\n",
    "    \n",
    "    handle = Entrez.esearch(db = \"pubmed\", retmax = \"100000\", retmode = \"xml\", \n",
    "                            term = q)\n",
    "\n",
    "    res = Entrez.read(handle)\n",
    "    \n",
    "    dis_cnt = res.get('Count')\n",
    "    \n",
    "    dis_ids = res.get('IdList')\n",
    "    \n",
    "    # Translated query (what actually got searched)\n",
    "    trans_q = res.get('QueryTranslation')\n",
    "    \n",
    "    dis_res.append([curr_row['disease'], curr_row['icd'], \n",
    "                    curr_row['icd_cat'], curr_row['icd_site'], dis_cnt, \n",
    "                    trans_q, dis_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_res_df = pd.DataFrame(dis_res, \n",
    "                          columns = ['Disease', 'icd', 'icd_cat', 'icd_site', \n",
    "                                     'count', 'query', 'PMIDs'])\n",
    "\n",
    "dis_res_df['icd_site'] = dis_res_df['icd_site'].apply(str)\n",
    "dis_res_df['icd_site'] = dis_res_df['icd_site'].str.zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_res_df.to_csv(f\"{HOME_DIR}/results/other/dis_only_py_pubmed_search.tsv\", \n",
    "                  sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pathogen only search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_res = []\n",
    "\n",
    "for x, curr_row in tqdm(orgs.iterrows(), total = orgs.shape[0]):\n",
    "    curr_org_name = curr_row['org_name']\n",
    "    curr_org_abbrev = curr_row['abbrev']\n",
    "    curr_org_mesh = curr_row['mesh_id']\n",
    "    \n",
    "    q = f\"(({curr_org_name}) OR ({curr_org_abbrev}) OR ({curr_org_mesh}))\"\n",
    "    \n",
    "    handle = Entrez.esearch(db = \"pubmed\", retmax = \"100000\", retmode = \"xml\", \n",
    "                            term = q)\n",
    "\n",
    "    res = Entrez.read(handle)\n",
    "    \n",
    "    # Number of articles found\n",
    "    org_cnt = res.get('Count')\n",
    "    \n",
    "    org_ids = res.get('IdList')\n",
    "    # Translated query (what actually got searched)\n",
    "    trans_q = res.get('QueryTranslation')\n",
    "    \n",
    "    org_res.append([curr_org_name, curr_org_abbrev, curr_org_mesh, org_cnt, \n",
    "                    trans_q, org_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_res_df = pd.DataFrame(org_res, \n",
    "                          columns = ['org_name', 'abbrev', 'mesh_id', 'count', \n",
    "                                     'query', 'PMIDs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_res_df.to_csv(f\"{HOME_DIR}/results/other/path_only_py_pubmed_search.tsv\",\n",
    "                   sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease-Pathogen Pair search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_res = []\n",
    "for x, curr_dis_row in tqdm(dis.iterrows(), total = dis.shape[0]):\n",
    "    curr_dis = curr_dis_row['disease']\n",
    "    \n",
    "    for y, curr_org_row in orgs.iterrows():\n",
    "        curr_org_name = curr_org_row['org_name']\n",
    "        curr_org_abbrev = curr_org_row['abbrev']\n",
    "        curr_org_mesh = curr_org_row['mesh_id']\n",
    "    \n",
    "        q = f\"(({curr_dis}) AND (({curr_org_name}) OR ({curr_org_abbrev}) OR ({curr_org_mesh})))\"\n",
    "    \n",
    "        handle = Entrez.esearch(db = \"pubmed\", retmax = \"100000\", \n",
    "                                retmode = \"xml\", term = q)\n",
    "\n",
    "        res = Entrez.read(handle)\n",
    "    \n",
    "        # Number of articles found\n",
    "        pair_cnt = res.get('Count')\n",
    "    \n",
    "        pair_ids = res.get('IdList')\n",
    "        \n",
    "        # Translated query (what actually got searched)\n",
    "        trans_q = res.get('QueryTranslation')\n",
    "        \n",
    "        pair_res.append([curr_dis, curr_dis_row['icd'], \n",
    "                         curr_dis_row['icd_cat'], curr_dis_row['icd_site'],\n",
    "                         curr_org_name, curr_org_abbrev, curr_org_mesh, \n",
    "                         pair_cnt, trans_q, pair_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_res_df = pd.DataFrame(pair_res, \n",
    "                          columns = ['Disease', 'icd', 'icd_cat', 'icd_site',\n",
    "                                     'org_name', 'abbrev', 'mesh_id', 'count', \n",
    "                                     'query', 'PMIDs'])\n",
    "\n",
    "pair_res_df['icd_site'] = pair_res_df['icd_site'].apply(str)\n",
    "pair_res_df['icd_site'] = pair_res_df['icd_site'].str.zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_res_df.to_csv(f\"{HOME_DIR}/results/other/pairs_py_pubmed_search.tsv\", \n",
    "                   sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate LPF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(left = pair_res_df, \n",
    "                 right = org_res_df[['abbrev','count', 'query']],\n",
    "                 on = \"abbrev\")\n",
    "\n",
    "final.columns = ['Disease', 'icd', 'icd_cat', 'icd_site', 'org_name', 'abbrev',\n",
    "                   'mesh_id', 'pair_count', 'pair_query', 'pair_PMIDs',\n",
    "                 'org_count', 'org_query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(left = final, \n",
    "                 right = dis_res_df[['Disease', 'count', 'query']], \n",
    "                 on = \"Disease\")\n",
    "\n",
    "final.columns = ['Disease', 'icd', 'icd_cat', 'icd_site', 'org_name', 'abbrev',\n",
    "                 'mesh_id', 'pair_count', 'pair_query', 'pair_PMIDs', \n",
    "                 'org_count', 'org_query', 'dis_count', 'dis_query']\n",
    "\n",
    "final['pair_count'] = final['pair_count'].apply(int)\n",
    "final['org_count'] = final['org_count'].apply(int)\n",
    "final['dis_count'] = final['dis_count'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negated form of LPF\n",
    "dis_norm     = final['pair_count'] /final['dis_count']\n",
    "path_norm    = final['pair_count'] / final['org_count']\n",
    "final['lpf'] = -np.log10(dis_norm * path_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_excel(f\"{HOME_DIR}/results/pubmed_search.xlsx\", \n",
    "               index = False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
